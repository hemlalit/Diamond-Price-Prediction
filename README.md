# ğŸ’ Diamond Price Prediction using Regression

A machine learning project that explores and compares multiple regression algorithms to predict diamond prices based on key features from the dataset. The goal is to identify the most accurate model using Mean Squared Error (MSE) as the evaluation metric.

---

## ğŸ”§ Tech Stack
**Languages & Tools:**  
Python $|$ scikit-learn $|$ XGBoost $|$ LightGBM $|$ Pandas $|$ NumPy $|$ Matplotlib $|$ Seaborn $|$ Jupyter Notebook

---

## ğŸ“Š Dataset
- **Source:** [Kaggle - Diamond Price Dataset](https://www.kaggle.com/code/developerhem/regression-diamonds-price-prediction)
- **Features Used:** carat_weight, cut_quality, clarity, color, total_sales_price, depth_percent, table_percent, meas_length, meas_width, meas_depth, polish, symmetry, eye_clean, lab, cut, fluor_color, girdle_min, girdle_max, culet_size, culet_condition, fancy_color_intensity, fancy_color_dominant_color, fancy_color_secondary_color, fancy_color_overtone

---

## ğŸ§  Algorithms Implemented
- L1 Regression (Lasso)
- L2 Regression (Ridge)
- ElasticNet (L1 + L2)
- K-Nearest Neighbors Regression (KNN)
- Decision Tree Regressor
- Random Forest Regressor
- Support Vector Regressor (SVR)
- XGBoost Regressor
- LightGBM Regressor

---

## ğŸ“ˆ Evaluation Metric
- **Mean Squared Error (MSE)** used to compare performance.
- The model with the lowest MSE is selected as the best performer.

---

## ğŸš€ Highlights
- Performed in-depth EDA to understand trends and distributions.
- Visualized correlations and feature importance.
- Tuned hyperparameters for top-performing models.
- Final model trained and evaluated on test data for deployment readiness.

---


---

## ğŸ’¡ Future Work
- Streamlit-based UI for interactive model inference
- Real-time comparison dashboard for regressors

---

## ğŸ™Œ Author
**Hemlalit Mali**  
[GitHub](https://github.com/hemlalit) $|$ [LinkedIn](https://www.linkedin.com/in/hemlalit)

---

_â€œThe best model is the one that tells the story behind the price.â€_
